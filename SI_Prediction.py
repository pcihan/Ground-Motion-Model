# -*- coding: utf-8 -*-
"""Copy of SI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11BWtJwPmJzoiwNNV7IwAvCrHxtn0Ijv3
"""

pip install xgboost

import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.metrics import r2_score
import xgboost as xgb
import time
from scipy.stats import pearsonr
import matplotlib.pyplot as plt


df = pd.read_excel("SI.xlsx")


X = df.drop(columns=[df.columns[-1]])
y = df[df.columns[-1]]

xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)

kf = KFold(n_splits=5, shuffle=True, random_state=42)
rmse_list = []
r2_list = []
mape_list = []
r_list = []

all_true = []
all_preds = []

total_start_time = time.time()

for fold, (train_index, test_index) in enumerate(kf.split(X), 1):
    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]

    fold_start_time = time.time()

    xgb_model.fit(X_train, y_train)
    y_pred = xgb_model.predict(X_test)

    fold_end_time = time.time()
    fold_execution_time = fold_end_time - fold_start_time

    rmse = np.sqrt(np.mean((y_test - y_pred) ** 2))
    r2 = r2_score(y_test, y_pred)
    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
    r, _ = pearsonr(y_test, y_pred)

    rmse_list.append(rmse)
    r2_list.append(r2)
    mape_list.append(mape)
    r_list.append(r)

    all_true.extend(y_test)
    all_preds.extend(y_pred)

    print(f"Fold {fold} R²: {r2:.3f}, r: {r:.3f}, Fold Execution Time: {fold_execution_time:.3f} seconds")

total_end_time = time.time()
total_execution_time = total_end_time - total_start_time

print(f"\nAvg R² (XGBoost): {np.mean(r2_list):.3f}")
print(f"Avg r (XGBoost): {np.mean(r_list):.3f}")
print(f"Avg RMSE (XGBoost): {np.mean(rmse_list):.2f}")
print(f"Avg MAPE (XGBoost): {np.mean(mape_list):.1f}%")
print(f"\nTotal Execution Time: {total_execution_time:.3f} seconds")

results_df = pd.DataFrame({
    'Actual': all_true,
    'Predicted': all_preds
})
results_df.to_excel("XGBoost-predicted.xlsx", index=False)

plt.figure(figsize=(8, 6))
plt.scatter(all_true, all_preds, alpha=0.7, edgecolor='k')
plt.plot([min(all_true), max(all_true)], [min(all_true), max(all_true)], 'r--')
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.title("Actual vs Predicted Values (XGBoost)")
plt.grid(True)
plt.tight_layout()
plt.savefig("SI XGBoost.png", dpi=300)
plt.show()

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score
from sklearn.model_selection import KFold
import time
from scipy.stats import pearsonr
import matplotlib.pyplot as plt


df = pd.read_excel("SI.xlsx")

X = df.drop(columns=[df.columns[-1]])
y = df[df.columns[-1]]

rf_model = RandomForestRegressor(random_state=42)

kf = KFold(n_splits=5, shuffle=True, random_state=42)
rmse_list = []
r2_list = []
mape_list = []
r_list = []
all_true = []
all_preds = []

total_start_time = time.time()

for fold, (train_index, test_index) in enumerate(kf.split(X), 1):
    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]

    fold_start_time = time.time()

    rf_model.fit(X_train, y_train)
    y_pred = rf_model.predict(X_test)

    fold_end_time = time.time()
    fold_execution_time = fold_end_time - fold_start_time

    rmse = np.sqrt(np.mean((y_test - y_pred) ** 2))
    r2 = r2_score(y_test, y_pred)
    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
    r, _ = pearsonr(y_test, y_pred)
    rmse_list.append(rmse)
    r2_list.append(r2)
    mape_list.append(mape)
    r_list.append(r)

    all_true.extend(y_test)
    all_preds.extend(y_pred)

    print(f"Fold {fold} R²: {r2:.3f}, r: {r:.3f}, Fold Execution Time: {fold_execution_time:.3f} seconds")

total_end_time = time.time()
total_execution_time = total_end_time - total_start_time

print(f"\nAvg R² (Random Forest): {np.mean(r2_list):.3f}")
print(f"Avg r (Random Forest): {np.mean(r_list):.3f}")
print(f"Avg RMSE (Random Forest): {np.mean(rmse_list):.2f}")
print(f"Avg MAPE (Random Forest): {np.mean(mape_list):.1f}%")
print(f"\nTotal Execution Time: {total_execution_time:.3f} seconds")

results_df = pd.DataFrame({
    'Actual': all_true,
    'Predicted': all_preds
})
results_df.to_excel("RandomForest-predicted.xlsx", index=False)

plt.figure(figsize=(8, 6))
plt.scatter(all_true, all_preds, alpha=0.7, edgecolor='k')
plt.plot([min(all_true), max(all_true)], [min(all_true), max(all_true)], 'r--')
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.title("Actual vs Predicted Values (Random Forest)")
plt.grid(True)
plt.tight_layout()
plt.savefig("SI RandomForest.png", dpi=300)
plt.show()

import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score
from sklearn.model_selection import KFold
import time
from scipy.stats import pearsonr
import matplotlib.pyplot as plt

df = pd.read_excel("SI.xlsx")

X = df.drop(columns=[df.columns[-1]])
y = df[df.columns[-1]]

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

lr_model = LinearRegression()

kf = KFold(n_splits=5, shuffle=True, random_state=42)
rmse_list = []
r2_list = []
mape_list = []
r_list = []
all_true = []
all_preds = []

total_start_time = time.time()

for fold, (train_index, test_index) in enumerate(kf.split(X_scaled), 1):
    X_train, X_test = X_scaled[train_index], X_scaled[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]

    fold_start_time = time.time()

    lr_model.fit(X_train, y_train)
    y_pred = lr_model.predict(X_test)

    fold_end_time = time.time()
    fold_execution_time = fold_end_time - fold_start_time

    rmse = np.sqrt(np.mean((y_test - y_pred) ** 2))
    r2 = r2_score(y_test, y_pred)
    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
    r, _ = pearsonr(y_test, y_pred)

    rmse_list.append(rmse)
    r2_list.append(r2)
    mape_list.append(mape)
    r_list.append(r)

    all_true.extend(y_test)
    all_preds.extend(y_pred)

    print(f"Fold {fold} R²: {r2:.3f}, r: {r:.3f}, Fold Execution Time: {fold_execution_time:.3f} seconds")

total_end_time = time.time()
total_execution_time = total_end_time - total_start_time

print(f"\nAvg R² (Linear Regression): {np.mean(r2_list):.3f}")
print(f"Avg r (Linear Regression): {np.mean(r_list):.3f}")
print(f"Avg RMSE (Linear Regression): {np.mean(rmse_list):.2f}")
print(f"Avg MAPE (Linear Regression): {np.mean(mape_list):.1f}%")
print(f"\nTotal Execution Time: {total_execution_time:.3f} seconds")

results_df = pd.DataFrame({
    'Actual': all_true,
    'Predicted': all_preds
})
results_df.to_excel("LinearRegression-predicted.xlsx", index=False)

import matplotlib.pyplot as plt
plt.figure(figsize=(8, 6))
plt.scatter(all_true, all_preds, alpha=0.7, edgecolor='k')
plt.plot([min(all_true), max(all_true)], [min(all_true), max(all_true)], 'r--')  # y = x doğrusu
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.title("Actual vs Predicted Values (Linear Regression)")
plt.grid(True)
plt.tight_layout()
plt.savefig("SI LinearRegression.png", dpi=300)
plt.show()

import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import r2_score, mean_squared_error
import time
from scipy.stats import pearsonr
import matplotlib.pyplot as plt

df = pd.read_excel("SI.xlsx")
X = df.drop(columns=[df.columns[-1]])
y = df[df.columns[-1]]

kf = KFold(n_splits=5, shuffle=True, random_state=42)

gbr_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)

r2_list = []
rmse_list = []
mape_list = []
r_list = []

all_true = []
all_preds = []

total_start_time = time.time()

for fold, (train_index, test_index) in enumerate(kf.split(X), 1):
    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]

    fold_start_time = time.time()

    gbr_model.fit(X_train, y_train)
    gbr_preds = gbr_model.predict(X_test)

    r2 = r2_score(y_test, gbr_preds)
    rmse = np.sqrt(mean_squared_error(y_test, gbr_preds))
    mape = np.mean(np.abs((y_test - gbr_preds) / y_test)) * 100
    r, _ = pearsonr(y_test, gbr_preds)  # Pearson korelasyon katsayısı

    r2_list.append(r2)
    rmse_list.append(rmse)
    mape_list.append(mape)
    r_list.append(r)

    all_true.extend(y_test)
    all_preds.extend(gbr_preds)

    fold_end_time = time.time()
    fold_execution_time = fold_end_time - fold_start_time
    print(f"Fold {fold} R²: {r2:.3f}, r: {r:.3f}, Fold Execution Time: {fold_execution_time:.3f} seconds")

total_end_time = time.time()
total_execution_time = total_end_time - total_start_time

print(f"\nAvg R² (GBR): {np.mean(r2_list):.3f}")
print(f"Avg r (GBR): {np.mean(r_list):.3f}")
print(f"Avg RMSE (GBR): {np.mean(rmse_list):.2f}")
print(f"Avg MAPE (GBR): {np.mean(mape_list):.1f}%")
print(f"\nTotal Execution Time: {total_execution_time:.3f} seconds")

results_df = pd.DataFrame({
    'Actual': all_true,
    'Predicted': all_preds
})
results_df.to_excel("GBR-predicted.xlsx", index=False)

plt.figure(figsize=(8, 6))
plt.scatter(all_true, all_preds, alpha=0.7, edgecolor='k')
plt.plot([min(all_true), max(all_true)], [min(all_true), max(all_true)], 'r--')
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.title("Actual vs Predicted Values (GBR)")
plt.grid(True)
plt.tight_layout()
plt.savefig("SI GBR.png", dpi=300)
plt.show()

import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb
from sklearn.metrics import r2_score, mean_squared_error
import time
from scipy.stats import pearsonr
import matplotlib.pyplot as plt


df = pd.read_excel("SI.xlsx")
X = df.drop(columns=[df.columns[-1]])
y = df[df.columns[-1]]

kf = KFold(n_splits=5, shuffle=True, random_state=42)

r2_list = []
rmse_list = []
mape_list = []
r_list = []
all_true = []
all_preds = []
execution_time_list = []
total_start_time = time.time()

for fold, (train_index, test_index) in enumerate(kf.split(X), 1):
    fold_start_time = time.time()
    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
    xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)
    meta_model = LinearRegression()

    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]

    rf_model.fit(X_train, y_train)
    xgb_model.fit(X_train, y_train)

    rf_train = rf_model.predict(X_train)
    xgb_train = xgb_model.predict(X_train)
    stacked_train = np.column_stack((rf_train, xgb_train))
    meta_model.fit(stacked_train, y_train)

    rf_test = rf_model.predict(X_test)
    xgb_test = xgb_model.predict(X_test)
    stacked_test = np.column_stack((rf_test, xgb_test))
    final_preds = meta_model.predict(stacked_test)

    r2 = r2_score(y_test, final_preds)
    rmse = np.sqrt(mean_squared_error(y_test, final_preds))
    r, _ = pearsonr(y_test, final_preds)
    mape = np.mean(np.abs((y_test - final_preds) / y_test)) * 100

    fold_end_time = time.time()
    fold_execution_time = fold_end_time - fold_start_time
    execution_time_list.append(fold_execution_time)

    r2_list.append(r2)
    rmse_list.append(rmse)
    mape_list.append(mape)
    r_list.append(r)

    all_true.extend(y_test)
    all_preds.extend(final_preds)
    print(f"Fold {fold} R²: {r2:.3f}, r: {r:.3f}, Fold Execution Time: {fold_execution_time:.3f} seconds")

total_end_time = time.time()
total_execution_time = total_end_time - total_start_time

print(f"\nAvg R² (Stacking-LR): {np.mean(r2_list):.3f}")
print(f"Avg r (Stacking-LR): {np.mean(r_list):.3f}")
print(f"Avg RMSE (Stacking-LR): {np.mean(rmse_list):.2f}")
print(f"Avg MAPE (Stacking-LR): {np.mean(mape_list):.1f}%")

print(f"\nTotal Execution Time: {total_execution_time:.3f} seconds")

results_df = pd.DataFrame({
    'Actual': all_true,
    'Predicted': all_preds
})
results_df.to_excel("stacking_LR_predicted.xlsx", index=False)

plt.figure(figsize=(8, 6))
plt.scatter(all_true, all_preds, alpha=0.7, edgecolor='k')
plt.plot([min(all_true), max(all_true)], [min(all_true), max(all_true)], 'r--')  # y = x doğrusu
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.title("Actual vs Predicted Values (Stacking-LR)")
plt.grid(True)
plt.tight_layout()
plt.savefig("SI stacking_LR.png", dpi=300)
plt.show()

import pandas as pd
import numpy as np
import shap
import xgboost as xgb
from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

df = pd.read_excel("SI.xlsx")
X = df.drop(columns=[df.columns[-1]])
y = df[df.columns[-1]]

kf = KFold(n_splits=5, shuffle=True, random_state=42)

r2_list = []
rmse_list = []

all_shap_values = []
all_X_test = []

for train_index, test_index in kf.split(X):
    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]

    xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)
    xgb_model.fit(X_train, y_train)

    y_pred = xgb_model.predict(X_test)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = np.corrcoef(y_test, y_pred)[0, 1] ** 2

    r2_list.append(r2)
    rmse_list.append(rmse)

    explainer = shap.Explainer(xgb_model, X_train)
    shap_values = explainer(X_test)

    all_shap_values.append(shap_values.values)
    all_X_test.append(X_test)

combined_shap_values = np.vstack(all_shap_values)
combined_X_test = pd.concat(all_X_test)

shap.summary_plot(combined_shap_values, combined_X_test, feature_names=X.columns, max_display=24)
plt.savefig("SI SHAP.png", dpi=300)

import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.ensemble import GradientBoostingRegressor
import time
from scipy.stats import pearsonr
import matplotlib.pyplot as plt


df = pd.read_excel("SI.xlsx")
X = df.drop(columns=[df.columns[-1]])
y = df[df.columns[-1]]

kf = KFold(n_splits=5, shuffle=True, random_state=42)

rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)
meta_model_gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)

r2_list = []
rmse_list = []
mape_list = []
r_list = []
execution_time_list = []

all_true = []
all_preds = []

start_total_time = time.time()

for train_index, test_index in kf.split(X):
    fold_start_time = time.time()

    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
    xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)
    meta_model_gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)

    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]

    rf_model.fit(X_train, y_train)
    xgb_model.fit(X_train, y_train)

    rf_train = rf_model.predict(X_train)
    xgb_train = xgb_model.predict(X_train)
    stacked_train = np.column_stack((rf_train, xgb_train))
    meta_model_gbr.fit(stacked_train, y_train)

    rf_test = rf_model.predict(X_test)
    xgb_test = xgb_model.predict(X_test)
    stacked_test = np.column_stack((rf_test, xgb_test))
    final_preds = meta_model_gbr.predict(stacked_test)

    r2 = r2_score(y_test, final_preds)
    rmse = np.sqrt(mean_squared_error(y_test, final_preds))
    r, _ = pearsonr(y_test, final_preds)
    mape = np.mean(np.abs((y_test - final_preds) / y_test)) * 100

    fold_end_time = time.time()
    fold_execution_time = fold_end_time - fold_start_time
    execution_time_list.append(fold_execution_time)

    r2_list.append(r2)
    rmse_list.append(rmse)
    mape_list.append(mape)
    r_list.append(r)

    all_true.extend(y_test)
    all_preds.extend(final_preds)

    print(f"Fold {len(r2_list)} R²: {r2:.3f}, r: {r:.3f}, Fold Execution Time: {fold_execution_time:.3f} seconds")

avg_r2 = np.mean(r2_list)
avg_rmse = np.mean(rmse_list)
avg_mape = np.mean(mape_list)
avg_r = np.mean(r_list)
total_execution_time = time.time() - start_total_time  # Toplam zaman hesaplaması


print(f"\nAvg R² (Stacking-GBR): {avg_r2:.3f}")
print(f"Avg r (Stacking-GBR): {avg_r:.3f}")
print(f"Avg RMSE (Stacking-GBR): {avg_rmse:.2f}")
print(f"Avg MAPE (Stacking-GBR): {avg_mape:.1f}%")
print(f"\nTotal Execution Time: {total_execution_time:.3f} seconds")

results_df = pd.DataFrame({
    'Actual': all_true,
    'Predicted': all_preds
})
results_df.to_excel("Stacking-GBR-predicted.xlsx", index=False)

plt.figure(figsize=(8, 6))
plt.scatter(all_true, all_preds, alpha=0.7, edgecolor='k')
plt.plot([min(all_true), max(all_true)], [min(all_true), max(all_true)], 'r--')  # y = x doğrusu
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.title("Actual vs Predicted Values (Stacking-GBR)")
plt.grid(True)
plt.tight_layout()
plt.savefig("SI Stacking-GBR.png", dpi=300)  # Görseli kaydet
plt.show()