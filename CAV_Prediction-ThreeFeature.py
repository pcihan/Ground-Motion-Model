# -*- coding: utf-8 -*-
"""3özellikTahmini-stakingGBR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BGyDKmNKuv9tbugTys-bQfuIU1Yg8Z9k
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.ensemble import GradientBoostingRegressor
import time
from scipy.stats import pearsonr

df = pd.read_excel("CAV_new.xlsx")
X = df.drop(columns=[df.columns[-1]])
y = df[df.columns[-1]]

kf = KFold(n_splits=5, shuffle=True, random_state=42)

r2_list = []
rmse_list = []
mape_list = []
r_list = []
execution_time_list = []
start_total_time = time.time()

for train_index, test_index in kf.split(X):
    fold_start_time = time.time()

    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
    xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)
    meta_model_gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)

    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]

    rf_model.fit(X_train, y_train)
    xgb_model.fit(X_train, y_train)

    rf_train = rf_model.predict(X_train)
    xgb_train = xgb_model.predict(X_train)
    stacked_train = np.column_stack((rf_train, xgb_train))
    meta_model_gbr.fit(stacked_train, y_train)

    rf_test = rf_model.predict(X_test)
    xgb_test = xgb_model.predict(X_test)
    stacked_test = np.column_stack((rf_test, xgb_test))
    final_preds = meta_model_gbr.predict(stacked_test)

    r2 = r2_score(y_test, final_preds)
    rmse = np.sqrt(mean_squared_error(y_test, final_preds))
    r, _ = pearsonr(y_test, final_preds)
    mape = np.mean(np.abs((y_test - final_preds) / y_test)) * 100

    fold_end_time = time.time()
    fold_execution_time = fold_end_time - fold_start_time
    execution_time_list.append(fold_execution_time)

    r2_list.append(r2)
    rmse_list.append(rmse)
    mape_list.append(mape)
    r_list.append(r)

    print(f"Fold {len(r2_list)} R²: {r2:.3f}, r: {r:.3f}, Fold Execution Time: {fold_execution_time:.3f} seconds")

avg_r2 = np.mean(r2_list)
avg_rmse = np.mean(rmse_list)
avg_mape = np.mean(mape_list)
avg_r = np.mean(r_list)
total_execution_time = time.time() - start_total_time

print(f"\nAvg RMSE (Stacking-GBR): {avg_rmse:.2f}")
print(f"Avg R² (Stacking-GBR): {avg_r2:.3f}")
print(f"Avg r (Stacking-GBR): {avg_r:.3f}")
print(f"Avg MAPE (Stacking-GBR): {avg_mape:.1f}%")
print(f"\nTotal Execution Time: {total_execution_time:.3f} seconds")

import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.ensemble import GradientBoostingRegressor
import time
from scipy.stats import pearsonr

df = pd.read_excel("SI_new.xlsx")
X = df.drop(columns=[df.columns[-1]])
y = df[df.columns[-1]]

kf = KFold(n_splits=5, shuffle=True, random_state=42)

r2_list = []
rmse_list = []
mape_list = []
r_list = []
execution_time_list = []
start_total_time = time.time()

for train_index, test_index in kf.split(X):
    fold_start_time = time.time()

    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
    xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)
    meta_model_gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)

    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]

    rf_model.fit(X_train, y_train)
    xgb_model.fit(X_train, y_train)

    rf_train = rf_model.predict(X_train)
    xgb_train = xgb_model.predict(X_train)
    stacked_train = np.column_stack((rf_train, xgb_train))
    meta_model_gbr.fit(stacked_train, y_train)

    rf_test = rf_model.predict(X_test)
    xgb_test = xgb_model.predict(X_test)
    stacked_test = np.column_stack((rf_test, xgb_test))
    final_preds = meta_model_gbr.predict(stacked_test)

    r2 = r2_score(y_test, final_preds)
    rmse = np.sqrt(mean_squared_error(y_test, final_preds))
    r, _ = pearsonr(y_test, final_preds)
    mape = np.mean(np.abs((y_test - final_preds) / y_test)) * 100

    fold_end_time = time.time()
    fold_execution_time = fold_end_time - fold_start_time
    execution_time_list.append(fold_execution_time)

    r2_list.append(r2)
    rmse_list.append(rmse)
    mape_list.append(mape)
    r_list.append(r)

    print(f"Fold {len(r2_list)} R²: {r2:.3f}, r: {r:.3f}, Fold Execution Time: {fold_execution_time:.3f} seconds")

avg_r2 = np.mean(r2_list)
avg_rmse = np.mean(rmse_list)
avg_mape = np.mean(mape_list)
avg_r = np.mean(r_list)
total_execution_time = time.time() - start_total_time

print(f"\nAvg RMSE (Stacking-GBR): {avg_rmse:.2f}")
print(f"Avg R² (Stacking-GBR): {avg_r2:.3f}")
print(f"Avg r (Stacking-GBR): {avg_r:.3f}")
print(f"Avg MAPE (Stacking-GBR): {avg_mape:.1f}%")
print(f"\nTotal Execution Time: {total_execution_time:.3f} seconds")

import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.ensemble import GradientBoostingRegressor
import time
from scipy.stats import pearsonr

df = pd.read_excel("d20_80_new.xlsx")
X = df.drop(columns=[df.columns[-1]])
y = df[df.columns[-1]]

kf = KFold(n_splits=5, shuffle=True, random_state=42)

r2_list = []
rmse_list = []
mape_list = []
r_list = []
execution_time_list = []
start_total_time = time.time()

for train_index, test_index in kf.split(X):
    fold_start_time = time.time()

    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
    xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)
    meta_model_gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)

    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]

    rf_model.fit(X_train, y_train)
    xgb_model.fit(X_train, y_train)

    rf_train = rf_model.predict(X_train)
    xgb_train = xgb_model.predict(X_train)
    stacked_train = np.column_stack((rf_train, xgb_train))
    meta_model_gbr.fit(stacked_train, y_train)

    rf_test = rf_model.predict(X_test)
    xgb_test = xgb_model.predict(X_test)
    stacked_test = np.column_stack((rf_test, xgb_test))
    final_preds = meta_model_gbr.predict(stacked_test)

    r2 = r2_score(y_test, final_preds)
    rmse = np.sqrt(mean_squared_error(y_test, final_preds))
    r, _ = pearsonr(y_test, final_preds)
    mape = np.mean(np.abs((y_test - final_preds) / y_test)) * 100

    fold_end_time = time.time()
    fold_execution_time = fold_end_time - fold_start_time
    execution_time_list.append(fold_execution_time)

    r2_list.append(r2)
    rmse_list.append(rmse)
    mape_list.append(mape)
    r_list.append(r)

    print(f"Fold {len(r2_list)} R²: {r2:.3f}, r: {r:.3f}, Fold Execution Time: {fold_execution_time:.3f} seconds")

avg_r2 = np.mean(r2_list)
avg_rmse = np.mean(rmse_list)
avg_mape = np.mean(mape_list)
avg_r = np.mean(r_list)
total_execution_time = time.time() - start_total_time

print(f"\nAvg RMSE (Stacking-GBR): {avg_rmse:.2f}")
print(f"Avg R² (Stacking-GBR): {avg_r2:.3f}")
print(f"Avg r (Stacking-GBR): {avg_r:.3f}")
print(f"Avg MAPE (Stacking-GBR): {avg_mape:.1f}%")
print(f"\nTotal Execution Time: {total_execution_time:.3f} seconds")

import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.ensemble import GradientBoostingRegressor
import time
from scipy.stats import pearsonr

df = pd.read_excel("d5_95_new.xlsx")
X = df.drop(columns=[df.columns[-1]])
y = df[df.columns[-1]]

kf = KFold(n_splits=5, shuffle=True, random_state=42)

r2_list = []
rmse_list = []
mape_list = []
r_list = []
execution_time_list = []
start_total_time = time.time()

for train_index, test_index in kf.split(X):
    fold_start_time = time.time()

    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
    xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)
    meta_model_gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)

    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]

    rf_model.fit(X_train, y_train)
    xgb_model.fit(X_train, y_train)

    rf_train = rf_model.predict(X_train)
    xgb_train = xgb_model.predict(X_train)
    stacked_train = np.column_stack((rf_train, xgb_train))
    meta_model_gbr.fit(stacked_train, y_train)

    rf_test = rf_model.predict(X_test)
    xgb_test = xgb_model.predict(X_test)
    stacked_test = np.column_stack((rf_test, xgb_test))
    final_preds = meta_model_gbr.predict(stacked_test)

    r2 = r2_score(y_test, final_preds)
    rmse = np.sqrt(mean_squared_error(y_test, final_preds))
    r, _ = pearsonr(y_test, final_preds)
    mape = np.mean(np.abs((y_test - final_preds) / y_test)) * 100

    fold_end_time = time.time()
    fold_execution_time = fold_end_time - fold_start_time
    execution_time_list.append(fold_execution_time)

    r2_list.append(r2)
    rmse_list.append(rmse)
    mape_list.append(mape)
    r_list.append(r)

    print(f"Fold {len(r2_list)} R²: {r2:.3f}, r: {r:.3f}, Fold Execution Time: {fold_execution_time:.3f} seconds")

avg_r2 = np.mean(r2_list)
avg_rmse = np.mean(rmse_list)
avg_mape = np.mean(mape_list)
avg_r = np.mean(r_list)
total_execution_time = time.time() - start_total_time

print(f"\nAvg RMSE (Stacking-GBR): {avg_rmse:.2f}")
print(f"Avg R² (Stacking-GBR): {avg_r2:.3f}")
print(f"Avg r (Stacking-GBR): {avg_r:.3f}")
print(f"Avg MAPE (Stacking-GBR): {avg_mape:.1f}%")
print(f"\nTotal Execution Time: {total_execution_time:.3f} seconds")

import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.ensemble import GradientBoostingRegressor
import time
from scipy.stats import pearsonr

df = pd.read_excel("d5_75_new.xlsx")
X = df.drop(columns=[df.columns[-1]])
y = df[df.columns[-1]]

kf = KFold(n_splits=5, shuffle=True, random_state=42)

r2_list = []
rmse_list = []
mape_list = []
r_list = []
execution_time_list = []
start_total_time = time.time()

for train_index, test_index in kf.split(X):
    fold_start_time = time.time()

    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
    xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)
    meta_model_gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)

    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]

    rf_model.fit(X_train, y_train)
    xgb_model.fit(X_train, y_train)

    rf_train = rf_model.predict(X_train)
    xgb_train = xgb_model.predict(X_train)
    stacked_train = np.column_stack((rf_train, xgb_train))
    meta_model_gbr.fit(stacked_train, y_train)

    rf_test = rf_model.predict(X_test)
    xgb_test = xgb_model.predict(X_test)
    stacked_test = np.column_stack((rf_test, xgb_test))
    final_preds = meta_model_gbr.predict(stacked_test)

    r2 = r2_score(y_test, final_preds)
    rmse = np.sqrt(mean_squared_error(y_test, final_preds))
    r, _ = pearsonr(y_test, final_preds)
    mape = np.mean(np.abs((y_test - final_preds) / y_test)) * 100

    fold_end_time = time.time()
    fold_execution_time = fold_end_time - fold_start_time
    execution_time_list.append(fold_execution_time)

    r2_list.append(r2)
    rmse_list.append(rmse)
    mape_list.append(mape)
    r_list.append(r)
    print(f"Fold {len(r2_list)} R²: {r2:.3f}, r: {r:.3f}, Fold Execution Time: {fold_execution_time:.3f} seconds")

avg_r2 = np.mean(r2_list)
avg_rmse = np.mean(rmse_list)
avg_mape = np.mean(mape_list)
avg_r = np.mean(r_list)
total_execution_time = time.time() - start_total_time

print(f"\nAvg RMSE (Stacking-GBR): {avg_rmse:.2f}")
print(f"Avg R² (Stacking-GBR): {avg_r2:.3f}")
print(f"Avg r (Stacking-GBR): {avg_r:.3f}")
print(f"Avg MAPE (Stacking-GBR): {avg_mape:.1f}%")
print(f"\nTotal Execution Time: {total_execution_time:.3f} seconds")